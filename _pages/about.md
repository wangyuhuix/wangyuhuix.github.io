---
permalink: /
title: "Personal Profile"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

 I received my Ph.D. in the College of Computer Science and Technology from Nanjing University of Aeronautics and Astronautics (NUAA), supervised by Professor [Xiaoyang Tan](http://parnec.nuaa.edu.cn/xtan/) in 2021. I received my M.S. degree in software engineering from NUAA in 2017. 

My research interests focus on reinforcement learning, especially on multi-step off-policy learning and the ones involving uncertainty or hidden information  .

I am currently serving as a reviewer for NeurIPS’2020,2021, ICLR’2021,2022, ICML’2021.



# Publications

1. Y. Wang, H. He, X. Tan, Y. Gan. Trust Region-Guided Proximal Policy Optimization. 2019. NeurIPS. [Link](https://papers.nips.cc/paper/2019/hash/a666587afda6e89aec274a3657558a27-Abstract.html)
2.	Y. Wang, X. Tan. Deep Recurrent Belief Propagation Network for POMDPs. 2021. AAAI. [Link](https://ojs.aaai.org/index.php/AAAI/article/view/17227)
3.	Y. Wang, H. He, X. Tan. Truly Proximal Policy Optimization. 2019. UAI. [Link](https://arxiv.org/abs/1903.07940)
4.	Y. Wang, X. Tan. Greedy Multi-step Off-Policy Reinforcement Learning. 2020. NeurIPS WorkShop on Deep RL. [Preprint](https://arxiv.org/abs/2102.11717)

[More Papers](publications)